{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94809118",
   "metadata": {},
   "source": [
    "# 2 БЛОК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#pip install category_encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV , cross_val_score , RandomizedSearchCV,KFold,RepeatedKFold\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder , LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, Lasso, Ridge , LogisticRegression , SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import get_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = pd.read_csv('dim_train.csv') # содержит только имя файла, без имен папок !!!\n",
    "df = pd.DataFrame(path_train)\n",
    "display(df.head(),df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['y'] == 0].index)\n",
    "df = df.drop(df[df['x'] == 0].index)\n",
    "df = df.drop(df[df['z'] == 0].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe962e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pairplot(df, hue = 'cut', palette= 'inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c53949",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x = 'price' , y = 'y', data = df, fit_reg= True, scatter_kws= {'color':'red'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x = 'price' , y = 'z', data = df, fit_reg= True, scatter_kws= {'color':'red'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e77d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x = 'price' , y = 'depth', data = df, fit_reg= True, scatter_kws= {'color':'red'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x = 'price' , y = 'table', data = df, fit_reg= True, scatter_kws= {'color':'red'}, line_kws={'color':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['x'] < 30 ]\n",
    "df = df[df['y'] < 30 ]\n",
    "df = df[(df['z'] < 30) & (df['z'] > 2)]\n",
    "df = df[(df['depth'] < 75) & (df['depth'] > 50) ]\n",
    "df = df[(df['table'] < 80) & (df['table'] > 45) ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ad419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep = 'last',ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408240da",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmap = df_map.corr()\n",
    "ax, f = plt.subplots(figsize = (12,9))\n",
    "sns.heatmap(corrmap, annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = df.copy()\n",
    "cat_feature = (df.dtypes == 'object')\n",
    "cat_features = list(cat_feature[cat_feature].index)\n",
    "le = LabelEncoder()\n",
    "\n",
    "for cat in cat_features:\n",
    "    df_map[cat] = le.fit_transform(df_map[cat])\n",
    "display(df_map.head())\n",
    "\n",
    "corrmap = df_map.corr()\n",
    "ax, f = plt.subplots(figsize = (12,9))\n",
    "sns.heatmap(corrmap, annot= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['cut','color']\n",
    "axis_features = ['x','y','z']\n",
    "num_features = ['carat','depth','table']\n",
    "y = np.array(df.price)\n",
    "X = df.drop(columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b149dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_transformer = Pipeline(steps=[\n",
    "    ('polynom', PolynomialFeatures(1,include_bias=False)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "clarity_map = [{\n",
    "    'col':'clarity',\n",
    "    'mapping':{'IF':7, 'VVS1':6, 'VVS2':5, 'VS1':4, 'VS2':3, \n",
    "               'SI1':2, 'SI2':1, 'I1':0}\n",
    "    }]\n",
    "\n",
    "clarity_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = clarity_map)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "    \n",
    "    \n",
    "CT = ColumnTransformer(transformers=[(\"pol_std\", axis_transformer, axis_features),\n",
    "                                               ('num', StandardScaler(), num_features),\n",
    "                                               ('cat', OneHotEncoder(), cat_features),\n",
    "                                               (\"ordinal_map\", clarity_transformer, ['clarity'])])\n",
    "display(CT)\n",
    "\n",
    "X_train_CT = CT.fit_transform(X_train)\n",
    "X_train_ = pd.DataFrame(X_train_CT)\n",
    "X_test_ = pd.DataFrame(CT.transform(X_test)) # тестовый кусок трансформируем как траин\n",
    "display(X_train_.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regmodel_param_test(\n",
    "    alphas_to_try, X, y, cv, scoring = 'neg_mean_absolute_percentage_error', \n",
    "    model_name = 'LASSO', X_test = None, y_test = None, \n",
    "    draw_plot = False, filename = None):\n",
    "    \n",
    "    validation_scores = []\n",
    "    train_scores = []\n",
    "    results_list = []\n",
    "    if X_test is not None:\n",
    "        test_scores = []\n",
    "        scorer = get_scorer(scoring)\n",
    "    else:\n",
    "        test_scores = None\n",
    "\n",
    "    for curr_alpha in alphas_to_try:\n",
    "        \n",
    "        if model_name == 'LASSO':\n",
    "            regmodel = Lasso(alpha = curr_alpha)\n",
    "        elif model_name == 'Ridge':\n",
    "            regmodel = Ridge(alpha = curr_alpha)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        results = cross_validate(\n",
    "            regmodel, X, y, scoring=scoring, cv=cv, \n",
    "            return_train_score = True)\n",
    "\n",
    "        validation_scores.append(np.mean(results['test_score']))\n",
    "        train_scores.append(np.mean(results['train_score']))\n",
    "        results_list.append(results)\n",
    "\n",
    "        if X_test is not None:\n",
    "            regmodel.fit(X,y)\n",
    "            y_pred = regmodel.predict(X_test)\n",
    "            test_scores.append(scorer(regmodel, X_test, y_test))\n",
    "    \n",
    "    chosen_alpha_id = np.argmax(validation_scores)\n",
    "    chosen_alpha = alphas_to_try[chosen_alpha_id]\n",
    "    max_validation_score = np.max(validation_scores)\n",
    "    if X_test is not None:\n",
    "        test_score_at_chosen_alpha = test_scores[chosen_alpha_id]\n",
    "    else:\n",
    "        test_score_at_chosen_alpha = None\n",
    "        \n",
    "    if draw_plot:\n",
    "        regmodel_param_plot(\n",
    "            validation_scores, train_scores, alphas_to_try, chosen_alpha, \n",
    "            scoring, model_name, test_scores, filename)\n",
    "    \n",
    "    return chosen_alpha, max_validation_score, test_score_at_chosen_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7e1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=15, n_repeats=3)\n",
    "#(n_splits = 15, shuffle=True, random_state= 42)\n",
    "lasso_alphas = np.linspace(1, 10, 10)\n",
    "\n",
    "chosen_alpha, max_validation_score, test_score_at_chosen_alpha = regmodel_param_test(\n",
    "        lasso_alphas, X_train_, y_train, \n",
    "        cv, scoring = 'neg_mean_absolute_percentage_error', model_name = 'LASSO', \n",
    "        X_test = X_test_, y_test = y_test, \n",
    "        draw_plot = True, filename = 'lasso_wide_search')\n",
    "\n",
    "print(\"Chosen alpha: %.5f\" % chosen_alpha)\n",
    "print(\"Validation score: %.5f\" % max_validation_score)\n",
    "print(\"Test score at chosen alpha: %.5f\" % test_score_at_chosen_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0557c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regmodel_param_plot(\n",
    "    validation_score, train_score, alphas_to_try, chosen_alpha,\n",
    "    scoring, model_name, test_score = None, filename = None):\n",
    "    \n",
    "    plt.figure(figsize = (8,8))\n",
    "    sns.lineplot(y = validation_score, x = alphas_to_try, \n",
    "                 label = 'validation_data')\n",
    "    sns.lineplot(y = train_score, x = alphas_to_try, \n",
    "                 label = 'training_data')\n",
    "    plt.axvline(x=chosen_alpha, linestyle='--')\n",
    "    if test_score is not None:\n",
    "        sns.lineplot(y = test_score, x = alphas_to_try, \n",
    "                     label = 'test_data')\n",
    "    plt.xlabel('alpha_parameter')\n",
    "    plt.ylabel(scoring)\n",
    "    plt.title(model_name + ' Regularisation')\n",
    "    plt.legend()\n",
    "    if filename is not None:\n",
    "        plt.savefig(str(filename) + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7555e44",
   "metadata": {},
   "source": [
    "# KNN Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_transformer = Pipeline(steps=[\n",
    "    ('polynom', PolynomialFeatures(2,include_bias=False)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "clarity_map = [{\n",
    "    'col':'clarity',\n",
    "    'mapping':{'IF':7, 'VVS1':6, 'VVS2':5, 'VS1':4, 'VS2':3, \n",
    "               'SI1':2, 'SI2':1, 'I1':0}}]\n",
    "\n",
    "clarity_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = clarity_map)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "      \n",
    "    \n",
    "CT = ColumnTransformer(transformers=[ (\"pol_std\", axis_transformer, axis_features),\n",
    "                                               ('num', StandardScaler(), num_features),\n",
    "                                               ('cat', OneHotEncoder(), cat_features),\n",
    "                                               (\"ordinal_map\", clarity_transformer, ['clarity'])])\n",
    "\n",
    "pipe = Pipeline([('preprocessing', CT ), \n",
    "                 ('regressor',KNeighborsRegressor())])\n",
    "\n",
    "cv = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "# Параметры для решетки(можно менять и смотреть)\n",
    "p = np.arange(2,4)         \n",
    "n_neighbors = [7,12,13]\n",
    "weights = ['uniform','distance']\n",
    "param_grid = [{\n",
    "     'regressor__p':p,\n",
    "     'regressor__n_neighbors': n_neighbors,\n",
    "     'regressor__weights': weights}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, return_train_score = True,cv=cv, n_jobs = -1,scoring= 'r2')\n",
    "grid.fit(X_train,y_train)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efcc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d30c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.DataFrame(grid.cv_results_)\n",
    "pv_table=table.pivot_table(index='param_regressor__p',columns='param_regressor__n_neighbors',values='mean_test_score')\n",
    "pv_table\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(pv_table, annot=True, linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------- Обучили и тестировали -------------------\")\n",
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=42)\n",
    "\n",
    "\n",
    "finish_pipe1 =  Pipeline([\n",
    "            ('preprocessing', CT), \n",
    "            ('regressor',     KNeighborsRegressor(n_neighbors = 7, p = 2, weights = 'distance'))\n",
    "            ])\n",
    "finish_pipe1.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe1.score(X_train,y_train))\n",
    "print(finish_pipe1.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(2, 15)\n",
    "pp = np.arange(1,4)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "for i, k, in enumerate(neighbors):\n",
    "    for p in (pp):\n",
    "        knn = KNeighborsRegressor(n_neighbors = k, p = p)\n",
    "        knn.fit(X_train_, y_train)\n",
    "        train_accuracy[i] = knn.score(X_train_, y_train)\n",
    "        test_accuracy[i] = knn.score(X_test_, y_test)\n",
    "\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.arange(1, 15):\n",
    "    knk = KNeighborsRegressor(n_neighbors=7, p = p)\n",
    "    strat_shuffle_split = KFold(n_splits=10)\n",
    "\n",
    "cross_vall = cross_val_score(knk, X_train_, y_train, cv=strat_shuffle_split)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"________________\")\n",
    "print(\"p=\",p)\n",
    "print(\"Значения правильности перекрестной проверки:\",cross_vall)\n",
    "print(\"Среднее:\",np.mean(cross_vall))\n",
    "print(\"Средняя квадоатическая ощибка (MSE):\",np.std(cross_vall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3df4ee",
   "metadata": {},
   "source": [
    "# Машин опорн вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c427d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_transformer = Pipeline(steps=[\n",
    "    ('polynom', PolynomialFeatures(1,include_bias=False)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "clarity_map = [{\n",
    "    'col':'clarity',\n",
    "    'mapping':{'IF':7, 'VVS1':6, 'VVS2':5, 'VS1':4, 'VS2':3, \n",
    "               'SI1':2, 'SI2':1, 'I1':0}}]\n",
    "\n",
    "clarity_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = clarity_map)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "      \n",
    "    \n",
    "CT = ColumnTransformer(transformers=[('axis', StandardScaler(), axis_features),\n",
    "                                               ('num', StandardScaler(), num_features),\n",
    "                                               ('cat', OneHotEncoder(), cat_features),\n",
    "                                               (\"ordinal_map\", clarity_transformer, ['clarity'])])\n",
    "\n",
    "pipe = Pipeline([('preprocessing',CT), \n",
    "                 ('classifier', svm.SVC(kernel='rbf'))])\n",
    "\n",
    "C = np.array([1,10,100]) #10**3,10**4, 10**5,10**6,10**7\n",
    "gamma = [0.1,1,5,10,100]\n",
    "\n",
    "param_grid =[{'classifier__C': C,\n",
    "     'classifier__gamma': gamma\n",
    "     }]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = 5, return_train_score=True)\n",
    "grid.fit(X_train,y_train)\n",
    "table=pd.DataFrame(grid.cv_results_)\n",
    "pv_table=table.pivot_table(index='param_classifier__C',columns='param_classifier__gamma',values='mean_test_score')\n",
    "pv_table\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(pv_table, annot=True, linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ee3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------- Обучили и тестировали -------------------\")\n",
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7efb11",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7db237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "axis_transformer = Pipeline(steps=[\n",
    "    ('polynom', PolynomialFeatures(2,include_bias=False)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "clarity_map = [{\n",
    "    'col':'clarity',\n",
    "    'mapping':{'IF':7, 'VVS1':6, 'VVS2':5, 'VS1':4, 'VS2':3, \n",
    "               'SI1':2, 'SI2':1, 'I1':0}}]\n",
    "\n",
    "clarity_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = clarity_map)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "#(\"pol_std\", axis_transformer, axis_features),\n",
    "      \n",
    "CT = ColumnTransformer(transformers=[('axis', StandardScaler(), axis_features),\n",
    "                                               ('num', StandardScaler(), num_features),\n",
    "                                               ('cat', OneHotEncoder(), cat_features),\n",
    "                                               (\"ordinal_map\", clarity_transformer, ['clarity'])])\n",
    "\n",
    "\n",
    "pipe = Pipeline([('preprocessing',CT), \n",
    "                 ('classifier', Lasso(max_iter = 300000, tol=1e-2))])\n",
    "\n",
    "C = np.array([0.001, 0.01,0.1,1,10,100,10**3, 10**4]) \n",
    "param_grid = [{'classifier__alpha': C}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = 10, return_train_score=True)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f68e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216deeaa",
   "metadata": {},
   "source": [
    "# SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT = ColumnTransformer(transformers=[('axis', StandardScaler(), axis_features),\n",
    "                                               ('num', StandardScaler(), num_features),\n",
    "                                               ('cat', OneHotEncoder(), cat_features),\n",
    "                                               (\"ordinal_map\", clarity_transformer, ['clarity'])])\n",
    "\n",
    "\n",
    "#pipe = Pipeline([('preprocessing',CT), \n",
    "                 #('model', SGDRegressor())])\n",
    "model = SGDRegressor(max_iter=3000000)\n",
    "\n",
    "#n_alphas = 200\n",
    "#alphas = np.logspace(-10, 0, n_alphas)\n",
    "#param_grid = {'alpha': alphas,\n",
    "\n",
    "\n",
    "param_grid = {'alpha': 10.0 ** -np.arange(1, 3),\n",
    "    'loss': ['squared_error', 'huber', 'epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling']\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(model, param_grid, cv = 10 , return_train_score=True)\n",
    "grid.fit(X_train_,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ed41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------- Обучили и тестировали -------------------\")\n",
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test_, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f0dbd",
   "metadata": {},
   "source": [
    "# RandomForest regr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceeb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis_transformer = Pipeline(steps=[\n",
    "  #  ('polynom', PolynomialFeatures(1,include_bias=False))])\n",
    "\n",
    "clarity_map = [{\n",
    "    'col':'clarity',\n",
    "    'mapping':{'IF':7, 'VVS1':6, 'VVS2':5, 'VS1':4, 'VS2':3, \n",
    "               'SI1':2, 'SI2':1, 'I1':0}\n",
    "    }]\n",
    "\n",
    "clarity_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = clarity_map))\n",
    "    ])\n",
    "\n",
    "#carat_transformer = Pipeline(steps=[\n",
    "#    ('bining',KBinsDiscretizer(n_bins=7, encode='ordinal'))\n",
    "#    ])\n",
    "    \n",
    "# для деревьев можно не стандартизировать данные в фичах \n",
    "CT = ColumnTransformer(transformers=[(\"pol_std\", 'passthrough', axis_features),\n",
    "                                               ('num', 'passthrough', num_features),\n",
    "                                               ('cat', OneHotEncoder(), cat_features),\n",
    "                                               (\"ordinal_map\", clarity_transformer, ['clarity'])])\n",
    "display(CT)\n",
    "\n",
    "X_CT = CT.fit_transform(X)\n",
    "#X_train_ = pd.DataFrame(X_train_CT)\n",
    "#X_test_ = pd.DataFrame(CT.transform(X_test)) # тестовый кусок трансформируем как траин\n",
    "display(X_CT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала выполняем код с СТ и потом уже здесь выполняем, тк изначально трансформ данные\n",
    "\n",
    "\n",
    "# Параметры для решетки(можно менять и смотреть)\n",
    "n_estimators = [5,10,45,50,70,75,80,85,90,100,200,300,400,500]\n",
    "max_features= [2,7,8,9,10,11,15,18,20,25,30]\n",
    "min_samples_leaf = [1,2,5,10,15]\n",
    "estimator = RandomForestRegressor()\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(estimator, param_grid, return_train_score = True, cv = 5 , n_jobs = -1, scoring= 'neg_mean_absolute_percentage_error')\n",
    "grid.fit(X_CT,y)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e125e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b676ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------- Обучили и тестировали -------------------\")\n",
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_CT, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e04c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25)\n",
    "\n",
    "finish_pipe_RFR =  Pipeline([\n",
    "            ('preprocessing', CT), \n",
    "            ('estimator',RandomForestRegressor(n_estimators = 200, min_samples_leaf = 1 , max_features = 25))\n",
    "            ])\n",
    "\n",
    "finish_pipe_RFR.fit(X, y)\n",
    "\n",
    "print(finish_pipe_RFR.score(X,y))\n",
    "\n",
    "#print(finish_pipe_RFR.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(n_estimators = 70, min_samples_leaf= 1 , max_features = 10)\n",
    "estimator.fit(X_train_,y_train)\n",
    "display(estimator.score(X_train_, y_train))\n",
    "estimator.score(X_test_, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84934be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train1 =[]\n",
    "sc_test1 = []\n",
    "sc_train2 =[]\n",
    "sc_test2 = []\n",
    "n_estimators = [10,25, 40, 50, 60, 70, 100, 200]\n",
    "for n in n_estimators:\n",
    "    rf = RandomForestRegressor(n_estimators= n,max_features= 10, min_samples_leaf = 1,random_state=0, n_jobs = -1)\n",
    "    rf.fit(X_train_, y_train)\n",
    "    sc_train_n = rf.score(X_train_, y_train)\n",
    "    sc_test_n = rf.score(X_test_, y_test)\n",
    "    sc_train1.append(sc_train_n)\n",
    "    sc_test1.append(sc_test_n)  \n",
    "    \n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "#ax2 = fig.add_subplot(122)\n",
    "ax1.plot(n_estimators,sc_train1)\n",
    "ax1.plot(n_estimators,sc_test1)\n",
    "ax1.set_ylim(0.95,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(RandomForestRegressor(n_estimators = 100, min_samples_leaf= 1 , max_features = 10), X_train_, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a433b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это код для того, чтобы сделать бины на данных - каратах\n",
    "# применяем его и потом делаем СТ(либо в блоке с СТ есть бин трансформер)\n",
    "#сильно не влияет на обучение модели, поэтому не применял\n",
    "kb = KBinsDiscretizer(n_bins = 4, encode='ordinal', strategy='uniform') # добавили strategy='uniform', по умолчанию была квантильная\n",
    "df['carat'] = kb.fit_transform(pd.DataFrame(df.carat))\n",
    "\n",
    "plt.subplots(1, figsize=(15,10))\n",
    "ax = sns.scatterplot(x = 'carat' , y = 'price', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377902c9",
   "metadata": {},
   "source": [
    "# БЛОК 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d40078",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = pd.read_csv('dim_train.csv') \n",
    "df = pd.DataFrame(path_train)\n",
    "display(df.head(),df.shape)\n",
    "\n",
    "path_test = pd.read_csv('dim_test.csv')\n",
    "df1 = pd.DataFrame(path_test)\n",
    "display(df1.head(),df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['y'] == 0].index)\n",
    "df = df.drop(df[df['x'] == 0].index)\n",
    "df = df.drop(df[df['z'] == 0].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['x'] < 30 ]\n",
    "df = df[df['y'] < 30 ]\n",
    "df = df[(df['z'] < 30) & (df['z'] > 2)]\n",
    "df = df[(df['depth'] < 75) & (df['depth'] > 50) ]\n",
    "df = df[(df['table'] < 80) & (df['table'] > 45) ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['cut','color']\n",
    "axis_features = ['x','y','z']\n",
    "num_features = ['carat','depth','table']\n",
    "y = np.array(df.price)\n",
    "X = df.drop(columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarity_map = [{\n",
    "    'col':'clarity',\n",
    "    'mapping':{'IF':7, 'VVS1':6, 'VVS2':5, 'VS1':4, 'VS2':3, \n",
    "               'SI1':2, 'SI2':1, 'I1':0}\n",
    "    }]\n",
    "\n",
    "clarity_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = clarity_map))\n",
    "    ])\n",
    "\n",
    "# для деревьев можно не стандартизировать данные в фичах \n",
    "CT = ColumnTransformer(transformers=[(\"axis\", 'passthrough', axis_features),\n",
    "                                               ('num', 'passthrough', num_features),\n",
    "                                               ('cat', OneHotEncoder(), cat_features),\n",
    "                                               (\"ordinal_map\", clarity_transformer, ['clarity'])])\n",
    "display(CT)\n",
    "\n",
    "#X_train_CT = CT.fit_transform(X_train)\n",
    "#X_train_ = pd.DataFrame(X_train_CT)\n",
    "#X_test = pd.DataFrame(CT.transform(X_test)) # тестовый кусок трансформируем как траин\n",
    "#display(X_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73db1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# есть 0 значения => убираем их\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584be61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут есть 2 нулевых значения\n",
    "df1 = df1.drop(df1[df1['y'] == 0].index)\n",
    "df1 = df1.drop(df1[df1['x'] == 0].index)\n",
    "df1 = df1.drop(df1[df1['z'] == 0].index)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем маску\n",
    "mask = df1.index\n",
    "#pd.DataFrame(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на данные, нужно ли будет убирать выбросы, как делали с df\n",
    "ax = sns.pairplot(df1, hue = 'cut', palette= 'inferno')\n",
    "# таких значительных выбросов нет, поэтому оставляем так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d16b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71696b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_pipe_RFR =  Pipeline([\n",
    "            ('preprocessing', CT), \n",
    "            ('estimator',RandomForestRegressor(n_estimators = 85, min_samples_leaf = 2 , max_features = 15))\n",
    "            ])\n",
    "\n",
    "finish_pipe_RFR.fit(X, y)\n",
    "print(finish_pipe_RFR.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bc9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = finish_pipe_RFR.predict(df1)\n",
    "y_predict.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
